<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>chatgpt on Brandontreb</title>
    <link>https://brandontreb.github.io/tags/chatgpt/</link>
    <description>Recent content in chatgpt on Brandontreb</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <managingEditor>brandontreb@gmail.com</managingEditor>
    <webMaster>brandontreb@gmail.com</webMaster>
    <lastBuildDate>Mon, 23 Jan 2023 23:55:39 +0000</lastBuildDate><atom:link href="https://brandontreb.github.io/tags/chatgpt/feed.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Prompt Leakage In AI Chat Systems</title>
      <link>https://brandontreb.github.io/2023/01/23/p79q7wz6hlqmckertv2y9/</link>
      <pubDate>Mon, 23 Jan 2023 23:55:39 +0000</pubDate>
      <author>brandontreb@gmail.com</author>
      <guid>https://brandontreb.github.io/2023/01/23/p79q7wz6hlqmckertv2y9/</guid>
      <description>With the rise of ChatGPT and other AI text interfaces, there emerges a new issue called Prompt Leakage. For these systems to work well, a carefully crafted prompt must be entered in order to give the AI very specific directions.
A prompt might be something as simple as &amp;ldquo;How many calories are in an apple?&amp;rdquo;, or it might be something much more complex (see below).
Lately, many startups have capitalized on these AI text systems and the &amp;ldquo;wizard behind the curtain&amp;rdquo; appears to be a super secret prompt.</description>
    </item>
    
  </channel>
</rss>
